{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"position-data-2024-02-01.csv\",on_bad_lines='skip')\n",
    "df2 = pd.read_csv(\"position-data-2024-02-02.csv\",on_bad_lines='skip')\n",
    "df3 = pd.read_csv(\"position-data-2024-02-03.csv\",on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2 , df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining missing values percentage function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missed_percentage(df):\n",
    "    missed = pd.DataFrame()\n",
    "    missed['column'] = df.columns\n",
    "    missed['percent'] = [round(100* df[col].isnull().sum() / len(df), 2) for col in df.columns]\n",
    "    missed = missed.sort_values('percent',ascending=False)\n",
    "    print(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  column  percent\n",
      "6     gs    15.44\n",
      "4    alt    11.29\n",
      "5     hd     0.06\n",
      "0     id     0.00\n",
      "1      t     0.00\n",
      "2     la     0.00\n",
      "3     lo     0.00\n"
     ]
    }
   ],
   "source": [
    "get_missed_percentage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the values wrt plane-id and time-t => this is because the no of unique planes that are traveling in 3 days are 1234. so we need to arrange the dataframe in such a way that  it will be easy for us to see which flight is coming at what time and altitute , speed , latiute and longitude of the flights at that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['id','t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By soritng wrt time we can see the real time get moment of the flight and as it is a continous sequential data , it is best suited to sort the values time and get the expected result\n",
    "\n",
    "Here we are interpolating the missing values to the nearest values -> this method takes from the nearst values and gives us a better result (as data doesn't vary much for consecutive seconds). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1234/1234 [09:31<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#dividing the df into values and filling it with the nearest values\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "flights = list(df['id'].unique())\n",
    "\n",
    "for a in tqdm(flights):\n",
    "    df_a = df[df['id'] == a]\n",
    "    df_a['gs'] = df_a['gs'].interpolate('nearest')\n",
    "    df_a['alt'] = df_a['alt'].interpolate('nearest')\n",
    "    df_a['hd'] = df_a['hd'].interpolate('nearest')\n",
    "    final_df = pd.concat([final_df, df_a], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  column  percent\n",
      "4    alt     1.17\n",
      "6     gs     0.72\n",
      "5     hd     0.01\n",
      "0     id     0.00\n",
      "1      t     0.00\n",
      "2     la     0.00\n",
      "3     lo     0.00\n"
     ]
    }
   ],
   "source": [
    "get_missed_percentage(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing null values if existing any after interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting final dataset\n",
    "\n",
    "final_df1 = final_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>la</th>\n",
       "      <th>lo</th>\n",
       "      <th>alt</th>\n",
       "      <th>hd</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.318204</td>\n",
       "      <td>0.050110</td>\n",
       "      <td>-0.059221</td>\n",
       "      <td>0.049382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>-0.318204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054795</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>-0.055987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alt</th>\n",
       "      <td>0.050110</td>\n",
       "      <td>-0.054795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042261</td>\n",
       "      <td>0.831798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hd</th>\n",
       "      <td>-0.059221</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>-0.042261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.172675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs</th>\n",
       "      <td>0.049382</td>\n",
       "      <td>-0.055987</td>\n",
       "      <td>0.831798</td>\n",
       "      <td>-0.172675</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           la        lo       alt        hd        gs\n",
       "la   1.000000 -0.318204  0.050110 -0.059221  0.049382\n",
       "lo  -0.318204  1.000000 -0.054795 -0.037640 -0.055987\n",
       "alt  0.050110 -0.054795  1.000000 -0.042261  0.831798\n",
       "hd  -0.059221 -0.037640 -0.042261  1.000000 -0.172675\n",
       "gs   0.049382 -0.055987  0.831798 -0.172675  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "data = final_df1[['la', 'lo', 'alt', 'hd', 'gs']]\n",
    "final_df1[['la', 'lo', 'alt', 'hd', 'gs']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(data,anamolies):\n",
    "    anomaly_count = anamolies.shape[0]\n",
    "    accuracy = 100*list(data['anomaly']).count(-1)/(anomaly_count)\n",
    "    print(\"Accuracy of the model:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining percentage of anamolies found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anamoly_percentage(df,ana):\n",
    "    s1,s2 = df.shape[0],ana.shape[0]\n",
    "    perc=((s2/s1)*100)\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Train the Isolation Forest model\n",
    "random_state = np.random.RandomState(42)\n",
    "model=IsolationForest(n_estimators=100,max_samples='auto',contamination=float(0.1),random_state=random_state)\n",
    "\n",
    "model.fit(data_scaled)\n",
    "predictions = model.predict(data_scaled)\n",
    "data['scores'] = model.decision_function(data)\n",
    "data['anomaly'] = predictions\n",
    "\n",
    "anomalies = data[data['anomaly'] == -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310267, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(data,anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that Isolation forest works better and i will work better in the scenarios if labeled data is provided earlier or semi supervised cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
